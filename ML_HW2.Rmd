---
title: "Machine Learning HW2"
author: "Javier Gutierrez & Andrea Pineda"
date: "1/28/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Data Review

```{r}

library(kknn)
library(ggplot2)
library(boot)
library(rpart)
library(rpart.plot)
```

```{r}
download.file(
"https://github.com/ChicagoBoothML/MLClassData/raw/master/UsedCars/UsedCars.csv",
"UsedCars.csv")

cars_data <- read.csv("UsedCars.csv")


download.file("https://raw.githubusercontent.com/ChicagoBoothML/HelpR/master/docv.R", "docv.R")

source("docv.R") 


```

### 2. TRAIN - TEST SPLIT

```{r}
train <- sample.int(nrow(cars_data), replace=FALSE, size = floor(.75*nrow(cars_data)))
train_cars<- cars_data[train, ]
test_cars <- cars_data[-train, ]

```


### 3. OLS MODEL & PLOT

```{r}

ols_cars <- lm(price ~mileage, 
                 data = train_cars)

train_cars$ols <- ols_cars$fitted.values

summary(ols_cars)
```

```{r}


ggplot(train_cars, aes(x = mileage, y = price)) + geom_point(alpha = .5, color = 'blue') + geom_line(aes(x = mileage, y = ols))


```

### POLYNOMIAL MODEL

```{r}

set.seed(17)

pol_n = 10

cv.error =rep(0,pol_n)
for (i in 1:pol_n ){
 glm.fit = glm(price ~ poly(mileage ,i),data=train_cars)
  cv.error[i]=cv.glm(train_cars ,glm.fit, K = 5)$delta [1]
}
cv.error

pol_n = 1:10

cv_poly = data.frame(pol_n, cv.error)

##cv_poly[which.min(cv.error)]

ggplot(cv_poly) + geom_line(aes(pol_n, cv.error)) + scale_x_discrete(limits = 1:10)

### 5


```



```{r}

degree = 5
glm.fit_train = glm(price ~ poly (mileage , degree), data = train_cars)

summary(glm.fit_train)


```



```{r}

train_cars$fit <- glm.fit_train$fitted.values

train_cars$fit <- predict(glm.fit_train)


ggplot(train_cars) + geom_point(aes(x = mileage, y = price), alpha = .5, color = 'blue') + geom_line(aes(x = mileage, y = fit))

```

### 5. KNN & REGRESSION TREES


```{r}

## KNN

set.seed(99)

kv = seq(from= 392, to=410, length.out = 10)

cv1 = docvknn(matrix(train_cars$mileage,ncol=1), train_cars$price,kv,nfold=5)

cv1


k_plot = data.frame(kv,cv1)

## CV ERROR PLOT

ggplot(k_plot, aes(x,cv1)) + geom_line()


## OPTIMAL K & FITTED VALUES

kbest = kv[which.min(cv1)]

kbest

kfbest = kknn(price~mileage,train_cars,data.frame(mileage=sort(train_cars$mileage)), k=kbest,kernel = "rectangular")


train_cars$fit_k <- kfbest$fitted.values

## PLOTS

#plot(train_cars$mileage,train_cars$price,cex.lab=1.2)
#lines(sort(train_cars$mileage),kfbest$fitted,col="red",lwd=2,cex.lab=2)


ggplot(train_cars, aes(x = mileage, y = price)) + geom_point(alpha = .5, color = 'blue') + 
  geom_line(aes(x = sort(mileage) , y = fit_k))


```


```{r}

## REGRESSION TREE

tree = rpart(price ~ mileage, data = train_cars, method = "anova", control = rpart.control(minsplit = 10, cp = 0.001)) 

## LEAFS

length(tree$frame$var[tree$frame$var=="<leaf>"])

## OPTIMAL PARAMETER CP

cptable = printcp(tree)
bestcp = cptable[ which.min(cptable[,"xerror"]), "CP" ]
bestcp


## PLOTS

rpart.plot(tree)

plotcp(tree)
```
```{r}

## REGRESSION TREE FITTED VALUES AND PLOT

train_cars$fit_tree <- predict(tree)

ggplot(train_cars, aes(x = mileage, y = price)) + geom_point(alpha = .5, color = 'blue') + geom_line(aes(x = mileage, y = fit_tree))


```
